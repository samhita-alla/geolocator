{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WinsonTruong/geolocator/blob/main/geolocator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqX1d86PkcFb"
      },
      "source": [
        "# Video/Image Geolocator\n",
        "\n",
        "Uses a [pre-trained GeoEstimation model](https://github.com/TIBHannover/GeoEstimation) to perform video/image inferencing.\n",
        "\n",
        "- Get the video/image path. If a YouTube video, download it.\n",
        "- If a video, retrieve video frames.\n",
        "- Perform model inferencing on video frames or an image.\n",
        "- Apply DBSCAN clustering on the predicted lats and longs.\n",
        "- Retrieve the dense cluster.\n",
        "- Compute mean of lats and longs of the data points belonging to the dense cluster.\n",
        "- Predict location and retrieve plotly graph.\n",
        "\n",
        "## BentoML\n",
        "\n",
        "- Create an ONNX version of the model.\n",
        "- Generate Bento.\n",
        "- Spin up the bento service.\n",
        "\n",
        "## Library dependencies\n",
        "\n",
        "- Katna\n",
        "- Youtube DL\n",
        "- Scikit Learn\n",
        "- PyTorch Lightning\n",
        "- s2sphere\n",
        "- Geopy\n",
        "- Gradio\n",
        "- ONNX\n",
        "- ONNX Runtime\n",
        "- BentoML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ERC4zjStDOv"
      },
      "outputs": [],
      "source": [
        "# install dependencies\n",
        "%pip install -q katna youtube_dl pytorch-lightning s2sphere scikit-learn gradio bentoml onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhchGk0zBR4H"
      },
      "outputs": [],
      "source": [
        "sh = \"\"\"\n",
        "URL=\"https://github.com/samhita-alla/GeoEstimation.git\"\n",
        "FOLDER=\"GeoEstimation\"\n",
        "if [ ! -d \"$FOLDER\" ] ; then\n",
        "    git clone $URL $FOLDER\n",
        "else\n",
        "    cd \"$FOLDER\"\n",
        "    git pull $URL\n",
        "fi\n",
        "\"\"\"\n",
        "\n",
        "with open(\"clone_script.sh\", \"w\") as file:\n",
        "  file.write(sh)\n",
        "\n",
        "!bash clone_script.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvV9V-UAtJhz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "in_colab = \"google.colab\" in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "  sh = \"\"\"\n",
        "  URL=\"https://github.com/samhita-alla/geolocator.git\"\n",
        "  FOLDER=\".\"\n",
        "  if [ ! -d \"$FOLDER\" ] ; then\n",
        "      git clone $URL $FOLDER\n",
        "  else\n",
        "      cd \"$FOLDER\"\n",
        "      git pull $URL\n",
        "  fi\n",
        "  \"\"\"\n",
        "\n",
        "  with open(\"clone_script.sh\", \"w\") as file:\n",
        "    file.write(sh)\n",
        "\n",
        "  !bash clone_script.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luMgNDX5tJh0"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy(\"services/bentoml/service.py\", \"GeoEstimation\")\n",
        "shutil.copy(\"app/post_processing.py\", \"GeoEstimation\")\n",
        "shutil.copy(\"app/pre_processing.py\", \"GeoEstimation\")\n",
        "shutil.copy(\"services/bentoml/bentofile.yaml\", \"GeoEstimation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3HnTwEWtJh0"
      },
      "outputs": [],
      "source": [
        "%cd GeoEstimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w470v4dJ0DJu"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import shutil\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "image_dir = None\n",
        "image_parent_dir = \"geolocator-images\"\n",
        "\n",
        "\n",
        "def display_video_frames(frames_directory: str):\n",
        "    frames = glob.glob(f\"{frames_directory}/*.jpeg\")\n",
        "\n",
        "    for frame in frames:\n",
        "        display(Image(filename=frame, width=200, height=100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_d8V7oHAKy7"
      },
      "outputs": [],
      "source": [
        "# download the model checkpoint & hyperparameters\n",
        "!mkdir -p models/base_M\n",
        "!wget https://github.com/TIBHannover/GeoEstimation/releases/download/pytorch/epoch.014-val_loss.18.4833.ckpt -O models/base_M/epoch=014-val_loss=18.4833.ckpt\n",
        "!wget https://github.com/TIBHannover/GeoEstimation/releases/download/pytorch/hparams.yaml -O models/base_M/hparams.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C66x3q6wCx1X"
      },
      "outputs": [],
      "source": [
        "!mkdir -p resources/s2_cells\n",
        "!wget -nc https://raw.githubusercontent.com/TIBHannover/GeoEstimation/original_tf/geo-cells/cells_50_5000.csv -O resources/s2_cells/cells_50_5000.csv\n",
        "!wget -nc https://raw.githubusercontent.com/TIBHannover/GeoEstimation/original_tf/geo-cells/cells_50_2000.csv -O resources/s2_cells/cells_50_2000.csv\n",
        "!wget -nc https://raw.githubusercontent.com/TIBHannover/GeoEstimation/original_tf/geo-cells/cells_50_1000.csv -O resources/s2_cells/cells_50_1000.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JONFjkWkA5ta"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "from generate_map import get_plotly_graph\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from geopy.geocoders import Nominatim\n",
        "from IPython.core.profiledir import LoggingConfigurable\n",
        "from post_processing import generate_prediction_logit\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def data_engineering(image_dir: str) -> pd.DataFrame:\n",
        "    inference_file_path = os.path.join(\n",
        "        \"models/base_M\",\n",
        "        f\"inference_{Path(os.path.join('/content', image_dir)).stem}.csv\",\n",
        "    )\n",
        "    inference_df = pd.read_csv(inference_file_path)\n",
        "    logging.info(f\"Inference DF: {inference_df.head()}\")\n",
        "\n",
        "    return inference_df\n",
        "\n",
        "\n",
        "def generate_prediction(image_dir: str, num_workers: int = 0) -> Tuple[str, plotly.graph_objects.Figure]:\n",
        "    # generate predictions on all the video frames\n",
        "    subprocess.run(\n",
        "        [\n",
        "            \"python\",\n",
        "            \"-m\",\n",
        "            \"classification.inference\",\n",
        "            \"--image_dir\",\n",
        "            image_dir,\n",
        "            \"--checkpoint\",\n",
        "            \"models/base_M/epoch=014-val_loss=18.4833.ckpt\",\n",
        "            \"--hparams\",\n",
        "            \"models/base_M/hparams.yaml\",\n",
        "            \"--num_workers\",\n",
        "            str(num_workers)\n",
        "        ],\n",
        "        capture_output=True,\n",
        "    )\n",
        "\n",
        "    # data engineering\n",
        "    inference_df = data_engineering(image_dir=image_dir)\n",
        "\n",
        "    # get location\n",
        "    location, latitude, longitude = generate_prediction_logit(\n",
        "        inference_df=inference_df\n",
        "    )\n",
        "\n",
        "    return location, get_plotly_graph(\n",
        "        latitude=latitude, longitude=longitude, location=location\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBmqdRsYastQ"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "\n",
        "from pre_processing import capture_frames, extract_youtube_video\n",
        "\n",
        "\n",
        "IMAGE_PARENT_DIR = \"geolocator-images\"\n",
        "\n",
        "\n",
        "def create_image_dir(img_file: str) -> str:\n",
        "    image_dir = os.path.join(IMAGE_PARENT_DIR, os.path.basename(img_file).split(\".\")[0])\n",
        "\n",
        "    # clear the image directory before filling it up\n",
        "    shutil.rmtree(image_dir, ignore_errors=True)\n",
        "    os.makedirs(image_dir)\n",
        "    shutil.copy(img_file, image_dir)\n",
        "\n",
        "    return image_dir\n",
        "\n",
        "\n",
        "def img_processor(img_file: str) -> Tuple[str, plotly.graph_objects.Figure]:\n",
        "    image_dir = create_image_dir(img_file=img_file)\n",
        "    return generate_prediction(image_dir=image_dir)\n",
        "\n",
        "\n",
        "def video_helper(\n",
        "    video_file: str, info_dict: Dict[str, Any]\n",
        ") -> Tuple[str, plotly.graph_objects.Figure]:\n",
        "    # capture frames\n",
        "    frames_directory = capture_frames(video_file_path=video_file, info_dict=info_dict)\n",
        "    display_video_frames(frames_directory=frames_directory)\n",
        "\n",
        "    image_dir = frames_directory\n",
        "    return generate_prediction(image_dir=image_dir)\n",
        "\n",
        "\n",
        "def video_processor(video_file: str) -> Tuple[str, plotly.graph_objects.Figure]:\n",
        "    info_dict = {\"id\": os.path.basename(video_file).split(\".\")[0]}\n",
        "    return video_helper(video_file=video_file, info_dict=info_dict)\n",
        "\n",
        "def url_processor(url: str) -> Tuple[str, plotly.graph_objects.Figure]:\n",
        "    video_file, info_dict = extract_youtube_video(url=url)\n",
        "    return video_helper(video_file=video_file, info_dict=info_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76htoqT2T4GZ"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "url_processor(url=\"https://www.youtube.com/watch?v=ADt1LnbL2HI\")\n",
        "# !wget -nc https://thumbs.dreamstime.com/b/santorini-island-greece-santorini-island-greece-oia-town-traditional-white-houses-churches-blue-domes-over-caldera-146011399.jpg\n",
        "# img_processor(\"santorini-island-greece-santorini-island-greece-oia-town-traditional-white-houses-churches-blue-domes-over-caldera-146011399.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaTTiiqbfBP5"
      },
      "source": [
        "# BentoML w/ ONNX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_0y-NqE0bsv"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "from classification.dataset import FiveCropImageDataset\n",
        "from classification.train_base import MultiPartitioningClassifier\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "model = MultiPartitioningClassifier.load_from_checkpoint(\n",
        "    checkpoint_path=\"models/base_M/epoch=014-val_loss=18.4833.ckpt\",\n",
        "    hparams_file=\"models/base_M/hparams.yaml\",\n",
        "    map_location=None,\n",
        ")\n",
        "\n",
        "!wget -nc https://thumbs.dreamstime.com/b/santorini-island-greece-santorini-island-greece-oia-town-traditional-white-houses-churches-blue-domes-over-caldera-146011399.jpg\n",
        "image_dir = create_image_dir(img_file=\"santorini-island-greece-santorini-island-greece-oia-town-traditional-white-houses-churches-blue-domes-over-caldera-146011399.jpg\")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    FiveCropImageDataset(meta_csv=None, image_dir=image_dir),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "images, meta_batch = next(iter(dataloader))\n",
        "cur_batch_size = images.shape[0]\n",
        "ncrops = images.shape[1]\n",
        "\n",
        "# reshape crop dimension to batch\n",
        "images = torch.reshape(images, (cur_batch_size * ncrops, *images.shape[2:]))\n",
        "\n",
        "model.to_onnx(\n",
        "  \"geolocator.onnx\",\n",
        "  input_sample=images,\n",
        "  export_params=True,\n",
        "  opset_version=11,\n",
        "  input_names=[\"input\"],\n",
        "  dynamic_axes={\n",
        "      \"input\": {0: \"batch_size\"},\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iHtF_MJA10P"
      },
      "outputs": [],
      "source": [
        "import onnxruntime\n",
        "\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return (\n",
        "        tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "    )\n",
        "\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"geolocator.onnx\")\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(images)}\n",
        "# ONNX Runtime will return a list of outputs\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "ort_outs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOEwFrpfveGg"
      },
      "outputs": [],
      "source": [
        "import bentoml\n",
        "import onnx\n",
        "\n",
        "\n",
        "bentoml.onnx.save_model(\"onnx_geolocator\", onnx.load(\"geolocator.onnx\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNGc5TdetJh7"
      },
      "outputs": [],
      "source": [
        "%cd GeoEstimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D48UkGm7kA0d"
      },
      "outputs": [],
      "source": [
        "# run bentoml service\n",
        "!bentoml serve service:svc --reload --port 3000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydzj3hvPZ8F2"
      },
      "source": [
        "# Gradio\n",
        "\n",
        "For the UI part, Gradio is being used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5I_XZIjNL_c"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# GeoLocator\")\n",
        "    gr.Markdown(\n",
        "        \"An app that guesses the location of an image ðŸŒŒ, a video ðŸ“¹ or a YouTube link ðŸ”—.\"\n",
        "    )\n",
        "    with gr.Tab(\"Image\"):\n",
        "        with gr.Row():\n",
        "            img_input = gr.Image(type=\"filepath\")\n",
        "            with gr.Column():\n",
        "                img_text_output = gr.Textbox(label=\"Location\")\n",
        "                img_plot = gr.Plot()\n",
        "        img_text_button = gr.Button(\"Go locate!\")\n",
        "    with gr.Tab(\"Video\"):\n",
        "        with gr.Row():\n",
        "            video_input = gr.Video(type=\"filepath\")\n",
        "            with gr.Column():\n",
        "                video_text_output = gr.Textbox(label=\"Location\")\n",
        "                video_plot = gr.Plot()\n",
        "        video_text_button = gr.Button(\"Go locate!\")\n",
        "    with gr.Tab(\"YouTube Link\"):\n",
        "        with gr.Row():\n",
        "            url_input = gr.Textbox(label=\"YouTube video link\")\n",
        "            with gr.Column():\n",
        "                url_text_output = gr.Textbox(label=\"Location\")\n",
        "                url_plot = gr.Plot()\n",
        "        url_text_button = gr.Button(\"Go locate!\")\n",
        "\n",
        "    img_text_button.click(\n",
        "        img_processor, inputs=img_input, outputs=[img_text_output, img_plot]\n",
        "    )\n",
        "    video_text_button.click(\n",
        "        video_processor, inputs=video_input, outputs=[video_text_output, video_plot]\n",
        "    )\n",
        "    url_text_button.click(\n",
        "        url_processor, inputs=url_input, outputs=[url_text_output, url_plot]\n",
        "    )\n",
        "\n",
        "    examples = gr.Examples(\n",
        "        examples=[\"https://www.youtube.com/watch?v=wxeQkJTZrsw\"], inputs=[url_input]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}